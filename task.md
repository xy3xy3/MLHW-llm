__实现简单对话的小型GPT——大作业2__

__问题描述：__

设计并实现一个基于Transformer架构的小型GPT，能够进行简单的对话。

请根据以下要求完成实验并提交报告和代码。

__数据集：__

数据集地址：
https://drive.google.com/file/d/1nEuew_KNpTMbyy7BO4c8bXMXN351RCPp/view

数据集大约有50万条数据，不一定要用到全部数据，也可以将较长的对话舍弃，可以根据自己电脑的算力情况调整。


情感分类数据集：


__任务要求：__

1\.数据预处理：

创建一个词汇表，将字符映射到唯一的 ID，并生成反向映射。

注意，除了需要将数据集中出现的字符映射为 ID 外，还需要一些额外的处理：

"<pad>"：用于填充的特殊标记。

"<unk>"：表示未知单词。

"<sep>"：分隔符，用于区分不同的文本片段或部分。例如：你喜欢什么？<sep>我喜欢学习。

2\.模型搭建与训练

基于Transformer实现一个小型GPT模型。

根据自己的算力情况设置合适的参数（训练轮数、解码器个数）

建议在训练过程中保存中间模型（比如每5个epoch保存一个checkpoint）

3\.对话生成：

实现一个简单的对话接口，能够接受用户输入并生成相应的回复。

4\. 微调实现情感分类

Extract

GPT

Linear

Text

Start

5\. 给定两个文本 Text1 和 Text2，如何微调 GPT 判断两个文本语义是否相似？

__实验报告（内容包括但不限于以下部分）：__

i\.数据预处理的方法

ii\.所实现的GPT模型的结构，以及参数

iii\.模型测试效果截图（最少3次交互对话，每次至少10句话）

iv\.情感分类的准确率（至少500条数据做测试，比较训练所有层 vs 仅训练输出层和最后一个transformer块，禁用mask结果怎么样及为什么）

vi\.如何实现判断文本语义相似度（只需回答问题无需训练模型，要详细，画图\+文字说明\+解释原因）

vii\.实验结果分析与讨论
